{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation With Markov Chains\n",
    "The main idea of today's workshop is to write some code that can generate text based on some collection of text (we call this text input a **corpus**). The corpus could be wikipedia articles, the words from novels or a library of tweets, basically any sort of textual data. \n",
    "\n",
    "The goal of the process is to gernerate **original** text that is in the same style as the original inputs.\n",
    "\n",
    "Therea are a number of different techniques that could be used to generate text and for this workshop we have chosen to use markov chains.  \n",
    "\n",
    "Before we get started we'll need to understand a little about markov chains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chains\n",
    "Markov chains are used to model stochastic **(random)** processes that have fixed states and transitions between these states that have probabilites attached to them. There's a lot going on in that sentence, so lets have an example! \n",
    "\n",
    "I have two choices for how to spend my afternoons. I could go to the gym or play video games. If I go to the gym on one day, I have 50% probability of going to the gym the following day (to try and keep up the good habits). If I play computer games on any afternoon I am highly-likely (80% probability) to play computer games the following day (yes I *am* addicted). \n",
    "\n",
    "The transitions from each choice must sum to **1**, so we can infer the chance of me playing video games after going to the gym is 50% and the chance of me going to the gym after playing computer games is 20%. \n",
    "\n",
    "The diagram below shows the relationship between the states and transitions. \n",
    "\n",
    "![Two state Markov chain](./images/markov_chain.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the model to generate a sequence of events, we need to pick a start state, and then generate a random value that will decide which state we move to. \n",
    "\n",
    "We have two choices when in each state, i.e. remain in the current state or move to the other. We will say that the interval 0 to X represents the chance of staying in the current state so for gym a number generated less than 0.5 will mean staying in the gym state and an number greater than or equal to 0.5 will transision us to the computer games state. For the computer games state Anything less than 0.8 will keep us playing games! \n",
    "\n",
    "Lets see this example in action. Highlight the cell below and run it to see what is generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting state Gym\n",
      "Day: 1 \t Chosen number: 0.863976293293202 \t New state: Games\n",
      "Day: 2 \t Chosen number: 0.6281904077274533 \t New state: Games\n",
      "Day: 3 \t Chosen number: 0.07419905270481642 \t New state: Games\n",
      "Day: 4 \t Chosen number: 0.8115552975991969 \t New state: Gym\n",
      "Day: 5 \t Chosen number: 0.10248274658397472 \t New state: Gym\n"
     ]
    }
   ],
   "source": [
    "import random #import the random library\n",
    "\n",
    "DAYS_TO_GENERATE = 5\n",
    "\n",
    "GYM_GYM = 0.5 #Probabilty of being in gym state and staying there\n",
    "GYM_GAMES = 0.5 #Probabilty of being in gym state moving to the games state\n",
    "\n",
    "GAMES_GAMES = 0.8 #We stay playing games if we played today\n",
    "GAMES_GYM = 0.2 #We go to the gym if we played today.\n",
    "\n",
    "current_state = \"Gym\" #Lets start with good intentions! \n",
    "\n",
    "print(\"Starting state {}\".format(current_state))\n",
    "\n",
    "for i in range(DAYS_TO_GENERATE):\n",
    "    \n",
    "    random_number = random.random() #Generate a random number\n",
    "    \n",
    "    if current_state == \"Gym\": \n",
    "        if random_number < GYM_GYM: #use the gym probabilities \n",
    "            current_state = \"Gym\"\n",
    "        else:\n",
    "            current_state = \"Games\"\n",
    "    else: \n",
    "        if random_number < GAMES_GAMES: #use the games probabilities \n",
    "            current_state = \"Games\"\n",
    "        else:\n",
    "            current_state = \"Gym\"\n",
    "\n",
    "    print(\"Day: {} \\t Chosen number: {} \\t New state: {}\".format(i+1, random_number, current_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 1 (5 minutes)\n",
    "Experiment with the code above. Here are some suggestions: \n",
    "1. Change the number of days generated\n",
    "2. Change the starting state\n",
    "3. Modify the transition probabilites "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data representation \n",
    "In the example above we defined variables to store the probabilities of the transitions. With large numbers of states this clearly wont be possible (the maximum number of transitions for $n$ states is $n^{2}$), so even with just 10 states there could be up to 100 transitions. \n",
    "\n",
    "Though not the optimal representation, one way to visualise the state transistions would be to place them in an array (or list in python), having them occur the number of times that represent their particular probabilities. \n",
    "\n",
    "For our inital example we could have some code as below: \n",
    "\n",
    "`\n",
    "gym_transitions = [\"Gym\",\"Games\"] #Represents one half probability of each transision\n",
    "games_transitions = [\"Games\", \"Games, \"Games\", \"Games\", \"Gym\"] #Represents 4/5 or 80% probability of games\n",
    "`\n",
    "\n",
    "If we do this then we can make use of the `choice` method in python's library to select from the options randomly.\n",
    "\n",
    "`current_state = random.choice(games_transitions)`\n",
    "\n",
    "Lets take a look at the example using the array based scheme. \n",
    "\n",
    "**Add in somthing on the hashmpa here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day: 1 \t Gym\n",
      "Day: 2 \t Games\n",
      "Day: 3 \t Games\n",
      "Day: 4 \t Games\n",
      "Day: 5 \t Games\n",
      "Day: 6 \t Games\n",
      "Day: 7 \t Gym\n",
      "Day: 8 \t Gym\n",
      "Day: 9 \t Gym\n",
      "Day: 10 \t Gym\n"
     ]
    }
   ],
   "source": [
    "gym_transitions = [\"Gym\",\"Games\"] #Represents one half probability of each transision\n",
    "games_transitions = [\"Games\", \"Games\", \"Games\", \"Games\", \"Gym\"] #Represents 4/5 or 80% probability of games\n",
    "\n",
    "current_state = \"Gym\"\n",
    "\n",
    "for i in range(10):\n",
    "    if current_state == \"Gym\":\n",
    "        current_state = random.choice(gym_transitions)\n",
    "    else:\n",
    "        current_state = random.choice(games_transitions)\n",
    "        \n",
    "    print(\"Day: {} \\t {}\".format(i+1, current_state))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 2\n",
    "There are two things to think about here: \n",
    "1. What does changing the representation do for us? \n",
    "2. There is a more memory efficent representation of data. Can you figure out what it might be? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with Text Generation\n",
    "Now we have a basic understanding of Markov chains, lets take a look at how they might apply in a text scenario. \n",
    "We'll use the following statement as a tiny corpus:\n",
    "\n",
    "\"Democracy is the best system of government. Dictatorship is the worst system of government\" \n",
    "\n",
    "Our first Markov chain considered only a single state when choosing what to do next. If we did that for text generation, we'd generate the next word based only on its predecessor. This would produce text that looks very close to the inputs. If we want to generate original text we'll have to consider more of the previous text to come up with something new. \n",
    "\n",
    "We also need to consider what will actually constitute a sentence. For our example we will: \n",
    "1. Expect a sentence to start with a capital letter\n",
    "2. End a sentence with a full stop\n",
    "\n",
    "The first thing to do is break down our example into two word segments, that we will use to build the keys of our transition matrix.\n",
    "\n",
    "0. Democracy is\n",
    "1. is the\n",
    "2. the best\n",
    "3. best system (Omitting lots of items here.....)\n",
    "7. of government\n",
    "\n",
    "We can then add the words that follow the word pairs into an array, where the probabilities will be set by the number of occurances of the following words\n",
    "\n",
    "`\n",
    "{\n",
    "    \"Democracy is\": [\"the\"],\n",
    "    \"is the\" : [\"best\", \"worst\"], #<-- Here is the magic, we have multiple options. \n",
    "    \"the best\" : [\"system\"],\n",
    "}\n",
    "`\n",
    "\n",
    "If we are able to build the hash up from the corpus we can apply the rules for our sentences to generate new sentences. The four valid outputs from this are: \n",
    "\n",
    "1. Democracy is the **best** system of government. \n",
    "2. Democracy is the **worst** system of government.\n",
    "3. Dictatorship is the **best** system of government.\n",
    "4. Dictatorship is the **worst** system of government. \n",
    "\n",
    "This is a very small example, but demonstrates the main concepts pretty well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a model\n",
    "To solve the problem of text generation, we'll break the problem up into two steps: \n",
    "1. Building the model from the corpus\n",
    "2. Generating new text from the model\n",
    "\n",
    "## Activity 3 (10 minutes)\n",
    "For this activity, we're going to code a simple function that builds our model. The function below takes a corpus of text as an input parameter and builds the hash of data for the model. There are some errors which need fixing before it works successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "def simple_model(corpus):\n",
    "    model = {} #An empty hash to store the values as they are added\n",
    "    \n",
    "    words = corpus.split() #Split the corpus up into individual words\n",
    "    \n",
    "    for i in range(len(words)-2): \n",
    "        phrase = \"{} {}\".format(words[i], words[i+1])\n",
    "        next_word = words[i+2]\n",
    "        \n",
    "        if phrase not in model:\n",
    "            model[phrase] = []\n",
    "        \n",
    "        model[phrase].append(next_word)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test the code is working on our simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Democracy is': ['the'],\n",
      " 'Dictatorship is': ['the'],\n",
      " 'best system': ['of'],\n",
      " 'government. Dictatorship': ['is'],\n",
      " 'is the': ['best', 'worst'],\n",
      " 'of government.': ['Dictatorship'],\n",
      " 'system of': ['government.', 'government.'],\n",
      " 'the best': ['system'],\n",
      " 'the worst': ['system'],\n",
      " 'worst system': ['of']}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "sample_corpus = \"Democracy is the best system of government. Dictatorship is the worst system of government.\"\n",
    "model = simple_model(sample_corpus)\n",
    "pprint.pprint(model)\n",
    "\n",
    "#Add in some test inputs of your own here. \n",
    "test_input = \"\"\n",
    "model = simple_model(test_input)\n",
    "pprint.pprint(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 3a (optional)\n",
    "If you have time, complete the function below which allows the number of states to be set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuneable_model(corpus, states=2):\n",
    "    model = {} #An empty hash to store the values as they are added\n",
    "    \n",
    "    words = corpus.split() #Split the corpus up into individual words\n",
    "    \n",
    "    for i in range(len(words)-states-1): \n",
    "        phrase = \" \".join(words[i:i+states])\n",
    "        next_word = words[i+states]\n",
    "        \n",
    "        if phrase not in model:\n",
    "            model[phrase] = []\n",
    "        \n",
    "        model[phrase].append(next_word)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again lets test the model in two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two state model\n",
      "================\n",
      "{'Democracy is': ['the'],\n",
      " 'Dictatorship is': ['the'],\n",
      " 'best system': ['of'],\n",
      " 'government. Dictatorship': ['is'],\n",
      " 'is the': ['best', 'worst'],\n",
      " 'of government.': ['Dictatorship'],\n",
      " 'system of': ['government.'],\n",
      " 'the best': ['system'],\n",
      " 'the worst': ['system'],\n",
      " 'worst system': ['of']}\n",
      "\n",
      "Three state model\n",
      "================\n",
      "{'Democracy is the': ['best'],\n",
      " 'Dictatorship is the': ['worst'],\n",
      " 'best system of': ['government.'],\n",
      " 'government. Dictatorship is': ['the'],\n",
      " 'is the best': ['system'],\n",
      " 'is the worst': ['system'],\n",
      " 'of government. Dictatorship': ['is'],\n",
      " 'system of government.': ['Dictatorship'],\n",
      " 'the best system': ['of'],\n",
      " 'the worst system': ['of']}\n"
     ]
    }
   ],
   "source": [
    "two_state_model = tuneable_model(sample_corpus,2)\n",
    "print(\"Two state model\")\n",
    "print(\"================\")\n",
    "pprint.pprint(two_state_model)\n",
    "\n",
    "print()\n",
    "\n",
    "three_state_model = tuneable_model(sample_corpus,3)\n",
    "print(\"Three state model\")\n",
    "print(\"================\")\n",
    "pprint.pprint(three_state_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating text from the model\n",
    "Now that you have a model in place you are ready to write a function that can process the model and generate new text from a starting point. Remember the two simple rules that we put in place around sentences: \n",
    "\n",
    "1. Sentences start with a capital letter\n",
    "2. Sentences end with a full stop. \n",
    "\n",
    "Were going to need to expand on them slightly:\n",
    "\n",
    "1. Sentences start with a capital letter **or an @ symbol** (To allow us to work with twitter data) \n",
    "2. Sentences end with a full stop **or an exclamation mark or question mark ** (Again twitter is a fiery place) \n",
    "\n",
    "## Activity 4 (10 minutes) \n",
    "\n",
    "Its your turn to implement some code that works on this now. In order to make this a little easier, I've broken it down into a number of functions that we can combine into a single `generate_text` model at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function reads the str parameter and decides if it is a valid starting point (i.e starts with a capital letter)\n",
    "def is_valid_start(str):\n",
    "    return str[0].isupper() or str[0] == \"@\"\n",
    "\n",
    "#This function reads a string parameter and decides if it is a valid end point\n",
    "def is_valid_end(str):\n",
    "    return str[-1] == \".\" or str[-1] == \"!\" or str[-1] == \"?\"\n",
    "\n",
    "#This function should produce the number of words in the string provided\n",
    "def words_in_string(str):\n",
    "    return len(str.split())\n",
    "\n",
    "def generate_text(model, sentences_to_generate=4, minimum_sentence_length=3):\n",
    "    \n",
    "    text = [] #An array of sentences\n",
    "    words_added = 0\n",
    "    for i in range(sentences_to_generate):\n",
    "        sentence = \"\"\n",
    "        #Choose a sentence starting location from the keys of the hash. Remember the rules!\n",
    "        starting_point = random.choice(list(model.keys()))\n",
    "        \n",
    "        while is_valid_start(starting_point) == False:\n",
    "            starting_point = random.choice(list(model.keys()))\n",
    "        \n",
    "        sentence += starting_point\n",
    "        \n",
    "        #Loop infinitely until we have reached the end of a word \n",
    "        while True: \n",
    "            key = \" \".join(sentence.split()[-2:])\n",
    "            \n",
    "            next_generated_word = random.choice(model[key])\n",
    "            \n",
    "            sentence += (\" \" + next_generated_word)\n",
    "            \n",
    "            if words_in_string(sentence) >= minimum_sentence_length and is_valid_end(sentence):\n",
    "                text.append(sentence)\n",
    "                break\n",
    "        \n",
    "        \n",
    "    return '\\n'.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the generation, using the original two sentence sample corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Democracy is the best system of government.\n",
      "Dictatorship is the best system of government.\n",
      "Dictatorship is the best system of government.\n"
     ]
    }
   ],
   "source": [
    "model = simple_model(sample_corpus)\n",
    "new_sentences = generate_text(model, 3)\n",
    "\n",
    "print(new_sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you now have generated some sentences that were not in the original corpus. Given the limited size of the inputs there really is not much that the system can do. Lets move on to experimenting with the system as a whole. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The system in action.......\n",
    "\n",
    "You've worked really hard to build the system above. A standard part of any machine learning project is the collection and cleansing of a dataset to train on. This can be a time consuming process so we have put together some pre-prepared data for this session. We have developed the following datasets:\n",
    "1. Taylor Swift lyrics\n",
    "2. Donald Trump Tweets\n",
    "3. A collection of scientific wikipedia articles\n",
    "4. Some BBC articles on business and the economy.\n",
    "\n",
    "We have wrapped these up into a single function called `fetch_corpus` that you can use to access the data sets as:\n",
    "1. `fetch_corpus('taylor')`\n",
    "2. `fetch_corpus('trump')`\n",
    "3. `fetch_corpus('wikipedia')`\n",
    "4. `fetch_corpus('bbc')`\n",
    "\n",
    "These all return a string that you can feed into your models. Right then time to experiment! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation\n",
    "If your code has worked so far with all of the tests, then you are good to go! If you've gone off-piste and haven't quite got it working then you can uncomment the import line in the code below to bring in some pre-written versions of the functions for experimentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Markov chain is the formal definition of a phospholipid outer membrane, and an intermembrane space.\n",
      "Dynkin, starting in the stock market as well as Norbert Wiener's work on special relativity in 1905, building on many theoretical results and empirical findings obtained by Albert Einstein: special relativity on two postulates:The laws of physics are the basis for general stochastic simulation methods known as diffusion processes, where he derived a set of Markov processes are the site of carboxylation in the creation of two further compounds that serve as short-term stores of energy, enabling its transfer to drive other reactions: these compounds are reduced nicotinamide adenine dinucleotide phosphate (NADPH) and adenosine triphosphate (ATP), the \"energy currency\" of cells.\n",
      "The Haber process was purchased by the light-dependent reactions, the resulting compounds are reduced nicotinamide adenine dinucleotide phosphate (NADPH) and adenosine triphosphate (ATP), the \"energy currency\" of cells.\n",
      "Frame-dragging: Rotating masses \"drag along\" the spacetime around them.\n",
      "Hilar fat and lymphatic tissue with lymph nodes surround these structures.\n",
      "The adjective Markovian is used to strip electrons from suitable substances, such as the asymptotic symmetry transformations.\n",
      "The superior pole of the days on which the position of the air, it is not used in the plasma membrane.\n",
      "In addition, running compressors takes considerable energy, as work must be done on the number of lobules arranged in an antenna-shaped structure named a photocomplex.\n",
      "The term mechanical digestion of the Earth) are physically identical.\n",
      "Claude proposed to have three or four converters with liquefaction steps in series, thereby omitting the need for a Lorentz factor correction.\n"
     ]
    }
   ],
   "source": [
    "#Uncomment the line(s) below to include the prewritten functions that you need\n",
    "#from markov_helper import simple_model\n",
    "#from markov_helper import tuneable_model\n",
    "\n",
    "from markov_helper import fetch_corpus\n",
    "\n",
    "corpus = fetch_corpus('wikipedia') #Choose a corpus \n",
    "\n",
    "#Setup the model \n",
    "model = simple_model(corpus)\n",
    "\n",
    "#Generate text\n",
    "new_sentences = generate_text(model, 10)\n",
    "\n",
    "print(new_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
