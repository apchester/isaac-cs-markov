{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation With Markov Chains\n",
    "The main idea of today's workshop is to write some code that can generate text based on some collection of text (we call this text input a **corpus**). The corpus could be wikipedia articles, the words from novels or a library of tweets, basically any sort of textual data. \n",
    "\n",
    "The goal of the process is to generate **original** text that is in the same *style* as the  input.\n",
    "\n",
    "Therea are a number of different techniques that could be used to generate text and for this workshop we have chosen to use Markov chains.  \n",
    "\n",
    "Before we get started we'll need to understand a little about Markov chains.\n",
    "\n",
    "## Markov Chains\n",
    "Markov chains are used to model stochastic **(random)** processes that have fixed states and transitions between them. The transitions have probabilites associated with them. There's a lot going on in those two sentences, so lets have an example! \n",
    "\n",
    "I have two choices for how to spend my afternoons. I could go to the gym or play video games. If I go to the gym on one day, I have 0.5 probability of going to the gym the following day (to try and keep up the good habits). If I play computer games on any afternoon I am highly-likely (0.8 probability) to play computer games the following day (yes I *am* addicted). \n",
    "\n",
    "The transitions from each choice must sum to **1**, so we can infer the chance of me playing video games after going to the gym is 50% and the chance of me going to the gym after playing computer games is 20%. \n",
    "\n",
    "The diagram below shows the relationship between the states and transitions. \n",
    "\n",
    "![Two state Markov chain](./images/markov_chain.png)\n",
    "\n",
    "\n",
    "To use the model to generate a sequence of events, we need to pick a start state, and then generate a random value that will decide which state we move to. \n",
    "\n",
    "We have two choices when in each state, i.e. remain in the current state or move to the other. We will say that the interval 0 to X represents the chance of staying in the current state so for gym a number generated less than 0.5 will mean staying in the gym state and an number greater than or equal to 0.5 will transision us to the computer games state. For the computer games state Anything less than 0.8 will keep us playing games! \n",
    "\n",
    "### Examples In This Notebook\n",
    "This notebook contains sections of code that can be edited and then run straight from the browser. To run the code, select the block and then click on the run button in the toolbar above. \n",
    "\n",
    "Lets see this example in action. Highlight the cell below and run it to see what is generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random #import the random library to generate random numbers.\n",
    "\n",
    "DAYS_TO_GENERATE = 5\n",
    "\n",
    "GYM_GYM = 0.5 #Probability of being in gym state and staying there\n",
    "GYM_GAMES = 0.5 #Probability of being in gym state moving to the games state\n",
    "\n",
    "GAMES_GAMES = 0.8 #We stay playing games if we played today\n",
    "GAMES_GYM = 0.2 #We go to the gym if we played today.\n",
    "\n",
    "current_state = \"Gym\" #Lets start with good intentions! \n",
    "\n",
    "print(\"Starting state: {}\".format(current_state))\n",
    "\n",
    "for i in range(DAYS_TO_GENERATE):\n",
    "    \n",
    "    random_number = random.random() #Generate a random number\n",
    "    \n",
    "    if current_state == \"Gym\": \n",
    "        if random_number < GYM_GYM: #use the gym probabilities \n",
    "            current_state = \"Gym\"\n",
    "        else:\n",
    "            current_state = \"Games\"\n",
    "    else: \n",
    "        if random_number < GAMES_GAMES: #use the games probabilities \n",
    "            current_state = \"Games\"\n",
    "        else:\n",
    "            current_state = \"Gym\"\n",
    "\n",
    "    print(\"Day: {} \\t Chosen number: {} \\t New state: {}\".format(i+1, random_number, current_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 1 (5 minutes)\n",
    "Experiment with the code above. Here are some suggestions: \n",
    "1. Change the number of days generated\n",
    "2. Change the starting state\n",
    "3. Modify the transition probabilites \n",
    "\n",
    "## Data representation \n",
    "In the example above we defined variables to store the probabilities of the transitions. With large numbers of states this clearly wont be possible (the maximum number of transitions for $n$ states is $n^{2}$ - everything state linked to every other state), so even with just 10 states there could be up to 100 transitions. \n",
    "\n",
    "Though not an optimal representation, one useful way to visualise the state transitions would be to place them in an array (or list in python), having them occur the number of times that represent their particular probabilities. \n",
    "\n",
    "For our inital example we could have some code as below: \n",
    "\n",
    "`gym_transitions = [\"Gym\",\"Games\"] #Represents one half probability of each transision\n",
    "games_transitions = [\"Games\", \"Games, \"Games\", \"Games\", \"Gym\"] #Represents 4/5 or 80% probability of games\n",
    "`\n",
    "\n",
    "If we do this then we can make use of the `choice` method in python's library to select from the options randomly.\n",
    "\n",
    "`current_state = random.choice(games_transitions)`\n",
    "\n",
    "Lets take a look at the example using the array based scheme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_transitions = [\"Gym\",\"Games\"] #Represents one half probability of each transision\n",
    "games_transitions = [\"Games\", \"Games\", \"Games\", \"Games\", \"Gym\"] #Represents 4/5 or 80% probability of games\n",
    "\n",
    "current_state = \"Gym\"\n",
    "\n",
    "for i in range(10):\n",
    "    if current_state == \"Gym\":\n",
    "        current_state = random.choice(gym_transitions)\n",
    "    else:\n",
    "        current_state = random.choice(games_transitions)\n",
    "        \n",
    "    print(\"Day: {} \\t {}\".format(i+1, current_state))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example looks much neater, and might even be a little easier to follow. There is stil one drawback to this approach in that we need to declare and store a variable for each state. \n",
    "\n",
    "This is fine for a small number of states, however later on we'll want to be able to give our text generation system any text and have it learn the states as it goes. \n",
    "\n",
    "A hashmap (or dictionary in python) allows us to set an identifying key for a value and then look it up later on. For example we could use the state as the key, and the list of values as the valuen stored under it. It would look a little like this:\n",
    "\n",
    "`\n",
    "{\n",
    "    \"Gym\" : [\"Gym\", \"Gym\"],\n",
    "    \"Games\" : [\"Gym\", \"Games\", \"Games\", \"Games\", \"Games\"]\n",
    "}\n",
    "`\n",
    "\n",
    "If we had a dictionary called states we could write `states['Gym']` and the dictionary would return the array with the gym's states. \n",
    "\n",
    "We can create keys at any time, and associate them with a value so this is tha approach we will use today. \n",
    "\n",
    "\n",
    "## Activity 2 (5 minutes)\n",
    "There are two things to think about here: \n",
    "1. What does changing the representation do for us? \n",
    "2. There is a more memory efficent representation of data. Can you figure out what it might be? \n",
    "\n",
    "## Getting Started with Text Generation\n",
    "Now we have a basic understanding of Markov chains, lets take a look at how they might apply in a text scenario. \n",
    "We'll use the following statement as a tiny corpus:\n",
    "\n",
    "**\"Democracy is the best system of government. Dictatorship is the worst system of government\"**\n",
    "\n",
    "Our first Markov chain considered only a single state when choosing what to do next. If we did that for text generation, we'd generate the next word based only on its predecessor. This would produce text that looks very close to the inputs. If we want to generate more original text we'll have to consider more of the previous text to come up with something new. \n",
    "\n",
    "We also need to consider what will actually constitute a sentence. For our example we will: \n",
    "1. Expect a sentence to start with a capital letter\n",
    "2. End a sentence with a full stop\n",
    "\n",
    "The first thing to do is break down our example into two word segments, that we will use to build the keys of our dictionary that will represent the transition matrix.\n",
    "\n",
    "0. Democracy is\n",
    "1. is the\n",
    "2. the best\n",
    "3. best system (Omitting lots of items here.....)\n",
    "7. of government\n",
    "\n",
    "We can then add the words that follow the word pairs into an array, where the probabilities will be set by the number of occurances of the following words as we discussed above. An excerpt from the created dictionary is below. \n",
    "\n",
    "`\n",
    "{\n",
    "    \"Democracy is\": [\"the\"],\n",
    "    \"is the\" : [\"best\", \"worst\"], #<-- Here is the magic, we have multiple options. \n",
    "    \"the best\" : [\"system\"],\n",
    "}\n",
    "`\n",
    "\n",
    "From our small example, there are two possibilites for choosing the word that follows \"is the\". The program will choose randomly between them to give us our output.\n",
    "\n",
    "\n",
    "If we are able to build the hash up from the corpus we can apply the rules for our sentences to generate new sentences. The four valid outputs from this are: \n",
    "\n",
    "1. Democracy is the **best** system of government. \n",
    "2. Democracy is the **worst** system of government.\n",
    "3. Dictatorship is the **best** system of government.\n",
    "4. Dictatorship is the **worst** system of government. \n",
    "\n",
    "This is a very small example, but demonstrates the main concepts pretty well. \n",
    "\n",
    "## Building a model\n",
    "To solve the problem of text generation, we'll break the problem up into two steps: \n",
    "1. Building the model from the corpus\n",
    "2. Generating new text from the model\n",
    "\n",
    "## Activity 3 (10 minutes)\n",
    "For this activity, we're going to code a simple function that builds our model. The function below takes a corpus of text as an input parameter and builds the hash of data for the model. There are some errors which need fixing before it works successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "def simple_model(corpus):\n",
    "    model = {} #An empty hash to store the values as they are added\n",
    "    \n",
    "    #We'll use a variable called words to store the individual words\n",
    "    words = \"\" #Split up the corpus into the individual words (see https://docs.python.org/3/library/stdtypes.html#str.split) for a hint\n",
    "    \n",
    "    #As we iterate through the list of words, we need to think about where to stop.\n",
    "    for i in range(len(words)): \n",
    "        phrase = \"{} {}\".format(words[i], words[i+1])\n",
    "        next_word = words[i+2]\n",
    "        \n",
    "        #If the phrase does not exist as a key in the model, add it and create an empty list to store the possible options.\n",
    "        if phrase not in model:\n",
    "            model[phrase] = []\n",
    "        \n",
    "        #Add in the possible transition into the list.\n",
    "        model[phrase].append(next_word)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test the code is working on our simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_corpus = \"Democracy is the best system of government. Dictatorship is the worst system of government.\"\n",
    "model = simple_model(sample_corpus)\n",
    "pprint.pprint(model)\n",
    "\n",
    "#Add in some test inputs of your own here. \n",
    "test_input = \"Add your own test input here.\"\n",
    "model = simple_model(test_input)\n",
    "pprint.pprint(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 3a (optional)\n",
    "\n",
    "I said we'll use the previous two words to generate the next one, but it would be nice to have a more generic version of the model that we could tune to suit our application. Experimenting with this might produce better output later on. \n",
    "\n",
    "If you have time, complete the function below which allows the number of states to be set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuneable_model(corpus, states=2):\n",
    "    model = {} #An empty hash to store the values as they are added\n",
    "    \n",
    "    words = #Complete this as above, splitting the supplied corpus into individual words.\n",
    "    \n",
    "    #Just a reminder that you might want to use python's list slicing to make this more generic\n",
    "    \n",
    "    for i in range(len(words)-states-1): \n",
    "        phrase = \" \".join() #Code here please :) \n",
    "        next_word = words[] #Which index is the next word? \n",
    "        \n",
    "    \n",
    "        #The next lines work as they did in the simpler function before. \n",
    "        if phrase not in model:\n",
    "            model[phrase] = []\n",
    "        \n",
    "        model[phrase].append(next_word)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again lets test the model in two ways on the original tiny corpus looking at two and three words. If we've written it correctly the two_state_model should be the same as the model produced by the `simple_model` function. You should be able to review the output for the three state model and see if is correct. This is one of the advantages of having a small test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_state_model = tuneable_model(sample_corpus,2)\n",
    "print(\"Two state model\")\n",
    "print(\"================\")\n",
    "pprint.pprint(two_state_model)\n",
    "\n",
    "print()\n",
    "\n",
    "three_state_model = tuneable_model(sample_corpus,3)\n",
    "print(\"Three state model\")\n",
    "print(\"================\")\n",
    "pprint.pprint(three_state_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating text from the model\n",
    "Now that you have a model in place you are ready to write a function that can process the model and generate new text from a starting point. Remember the two simple rules that we put in place around sentences: \n",
    "\n",
    "1. Sentences start with a capital letter\n",
    "2. Sentences end with a full stop. \n",
    "\n",
    "We are going to need to expand on them slightly to deal with more real world text:\n",
    "\n",
    "1. Sentences start with a capital letter **or an @ symbol** (To allow us to work with twitter data) \n",
    "2. Sentences end with a full stop **or an exclamation mark or question mark ** (Again twitter is a fiery place) \n",
    "\n",
    "## Activity 4 (10 minutes) \n",
    "\n",
    "Its your turn to implement some code that works on this now. In order to make this a little easier, I've broken it down into a number of functions that we can combine into a single `generate_text` model at the end. Specifically you will have to implement three helper methods below:\n",
    "\n",
    "1. `is_valid_start` should return True if the str parameter is a valid start for a sentence. \n",
    "2. `is_valid_end` should return True if the str parameter is a valid end of a sentence.\n",
    "3. `words_in_string` should return the number of words in the string provided. \n",
    "\n",
    "I have provided some tests to help you know when your code is ready. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function reads the str parameter and decides if it is a valid starting point (i.e starts with a capital letter)\n",
    "def is_valid_start(str):\n",
    "    return False\n",
    "\n",
    "#This function reads a string parameter and decides if it is a valid end point\n",
    "def is_valid_end(str):\n",
    "    return False\n",
    "\n",
    "#This function should produce the number of words in the string provided\n",
    "def words_in_string(str):\n",
    "    return 0\n",
    "\n",
    "print(\"Testing is_valid_start\")\n",
    "print(\"\\t Testing 'Hello' as valid start should be True: {}\".format(is_valid_start(\"Hello\")))\n",
    "print(\"\\t Testing 'hello' as valid start should be False: {}\".format(is_valid_start(\"hello\")))\n",
    "print(\"\\t Testing '@adam' as valid start should be True: {}\".format(is_valid_start(\"@adam\")))\n",
    "print(\"\\t Testing '!adam' as valid start should be False: {}\".format(is_valid_start(\"!adam\")))\n",
    "\n",
    "print(\"Testing is_valid_end\")\n",
    "print(\"\\t Testing 'end.' as valid end should be True: {}\".format(is_valid_end(\"end.\")))\n",
    "print(\"\\t Testing 'and,' as valid end should be False: {}\".format(is_valid_end(\"and,\")))\n",
    "print(\"\\t Testing 'fired!' as valid end should be True: {}\".format(is_valid_end(\"fired!\")))\n",
    "print(\"\\t Testing 'fired?' as valid end should be True: {}\".format(is_valid_end(\"fired?\")))\n",
    "\n",
    "print(\"Testing words_in_string\")\n",
    "print(\"\\t 'hello beautiful world!' should have length 3: {}\".format(words_in_string(\"hello beautiful world!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, sentences_to_generate=5, input_words=2, minimum_sentence_length=3):\n",
    "    \n",
    "    text = [] #An array of sentences\n",
    "    words_added = 0\n",
    "    for i in range(sentences_to_generate):\n",
    "        sentence = \"\"\n",
    "        #Choose a sentence starting location from the keys of the hash. Remember the rules!\n",
    "        starting_point = random.choice(list(model.keys()))\n",
    "        \n",
    "        while is_valid_start(starting_point) == False:\n",
    "            starting_point = random.choice(list(model.keys()))\n",
    "        \n",
    "        sentence += starting_point\n",
    "        \n",
    "        #Loop infinitely until we have reached the valid end of a sentence \n",
    "        while True: \n",
    "            key = \" \".join(sentence.split()[-input_words:])\n",
    "            \n",
    "            next_generated_word = random.choice(model[key])\n",
    "            \n",
    "            sentence += (\" \" + next_generated_word)\n",
    "            \n",
    "            if words_in_string(sentence) >= minimum_sentence_length and is_valid_end(sentence):\n",
    "                text.append(sentence)\n",
    "                break\n",
    "        \n",
    "        \n",
    "    return '\\n'.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the generation, using the original two sentence sample corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = simple_model(sample_corpus)\n",
    "new_sentences = generate_text(model)\n",
    "\n",
    "print(new_sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you now have generated some sentences that were not in the original corpus. Given the limited size of the inputs there really is not much that the system can do. Lets move on to experimenting with the system as a whole. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## The system in action.......\n",
    "\n",
    "You've worked really hard to build the system above. A standard part of any machine learning project is the collection and cleansing of a dataset to train on. This can be a time consuming process so we have put together some pre-prepared data for this session. We have developed the following datasets:\n",
    "1. Donald Trump tweets \n",
    "2. Taylor Swift lyrics\n",
    "3. A collection of scientific wikipedia articles\n",
    "4. Some BBC articles on business and the economy.\n",
    "\n",
    "We have wrapped these up into a single function called `fetch_corpus` that you can use to access the data sets as:\n",
    "1. `fetch_corpus('trump')`\n",
    "2. `fetch_corpus('taylor')`\n",
    "3. `fetch_corpus('wikipedia')`\n",
    "4. `fetch_corpus('bbc')`\n",
    "\n",
    "These all return a string that you can feed into your models. \n",
    "\n",
    "Right then time to experiment! \n",
    "\n",
    "## Experimentation (20 mins)\n",
    "If your code has worked so far with all of the tests, then you are good to go! If you've gone off-piste and haven't quite got it working then you can uncomment the import lines in the code below to bring in some pre-written versions of the functions for experimentation. \n",
    "\n",
    "When you have generated some interesting text, copy and paste it into the ideas tab of the slido wint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment the line below to include the prewritten functions if you need them\n",
    "# from markov_helper import simple_model, tuneable_model, is_valid_start, is_valid_end, words_in_string, generate_text\n",
    "\n",
    "from markov_helper import fetch_corpus\n",
    "\n",
    "corpus = fetch_corpus('trump') #Choose a corpus \n",
    "\n",
    "#Setup the model \n",
    "model = simple_model(corpus)\n",
    "\n",
    "#Generate text\n",
    "new_sentences = generate_text(model, 10)\n",
    "\n",
    "# #Try a more advanced model\n",
    "# previous_states = 3\n",
    "# minimum_length = 2\n",
    "# model = tuneable_model(corpus, previous_states)\n",
    "# #Remember the generate_text parameters are corpus, sentences to generate, input words and the minimum number of words in a sentence\n",
    "# new_sentences = generate_text(model, 10, previous_states, minimum_length)\n",
    "\n",
    "print(new_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "In this lab session we have used a relatively simple technique of markov chains to write code that generates text in the style of the original corpus. \n",
    "\n",
    "Though simple, some of the results look plausible and generating huge amounts of content is trivial. This ease of content generation makes it hard to establish whether content is genuine, especially when it is shared and reshared many times on social media platforms. \n",
    "\n",
    "\n",
    "## Going Further\n",
    "\n",
    "In this session we have explored a small part of a field of research called Natural Language Processing, which combines elements of linguistics, computer science and artificial intelligence. Work in this area supports generating automatic summares of documents, machine translation (converting from one langauge to another) and question answering (e.g What is the capital of France?) \n",
    "\n",
    "You are welcome to extend this work for your own purposes. If you are interested in the field of natural language procesing you might like to explore other tools and techniques. Here's a few that you might find interesting. \n",
    "\n",
    "### [Natural Language Toolkit](https://www.nltk.org)\n",
    "The Natural Language Toolkit (NLTK) is a fantastic Python library that includes a large number of functions to help with building NLP programs. The documentation is excellent. \n",
    "\n",
    "### Word Vectors \n",
    "If you explore the space further you will come across word vectors, which are learned relationships between words that are stored as vectors. The embeddings typically represent some meaning e.g. King - Man + Woman = Queen, where it knows that man/king is related to woman/queen. A good article can be found at [The Amazing Power of Word Vectors](https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/). \n",
    "\n",
    "### [Text Generation with an RNN](https://www.tensorflow.org/tutorials/text/text_generation)\n",
    "This tutorial covers character based text generation using a recurrent neural network. This is a more computationally intensive method than Markov chains, but it produces some interesting results. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
